import streamlit as st
import difflib
import pandas as pd
import numpy as np
import re
from datetime import datetime
from sentence_transformers import SentenceTransformer

# (Opcjonalnie) Google Sheets
try:
    import gspread
    from google.oauth2.service_account import Credentials
    GS_AVAILABLE = True
except Exception:
    GS_AVAILABLE = False

# ---------- USTAWIENIA STRONY ----------
st.set_page_config(page_title="Ocena tÅ‚umaczeÅ„ â€“ wersja nauczycielska", layout="wide")

# ---------- MODEL SEMANTYCZNY ----------
@st.cache_resource
def load_st_model():
    # Lekki model do porÃ³wnaÅ„ zdaÅ„ (ok. 22 MB)
    return SentenceTransformer("sentence-transformers/all-MiniLM-L6-v2")

def best_semantic_match(student_text: str, refs: list[str]):
    """Zwraca (best_score (0..1), best_ref)."""
    model = load_st_model()
    emb_student = model.encode(student_text, normalize_embeddings=True)
    emb_refs = model.encode(refs, normalize_embeddings=True)
    sims = [float(np.dot(emb_student, r)) for r in emb_refs]  # dot == cosine
    idx = int(np.argmax(sims))
    return sims[idx], refs[idx]

# ---------- POMOCNICZE (tekst globalnie) ----------
def compute_best_match(student_text: str, refs: list[str]):
    """Literalne podobieÅ„stwo; zwraca (best_score, best_ref, diff_preview_text)."""
    best_ref, best_score = "", 0.0
    for ref in refs:
        score = difflib.SequenceMatcher(None, student_text.lower(), ref.lower()).ratio()
        if score > best_score:
            best_score, best_ref = score, ref
    diff_tokens = list(difflib.ndiff(student_text.split(), (best_ref or "").split()))
    if len(diff_tokens) > 200:
        diff_tokens = diff_tokens[:200] + ["..."]
    diff_preview = " ".join(diff_tokens)
    return best_score, best_ref, diff_preview

def ensure_results_df():
    if "results_df" not in st.session_state:
        st.session_state.results_df = pd.DataFrame(
            columns=[
                "Data","Student","Zadanie/Plik",
                "PodobieÅ„stwo_literalne","PodobieÅ„stwo_semantyczne","Wynik_Å‚Ä…czny",
                "WiernoÅ›Ä‡(1-5)","JÄ™zyk(1-5)","Styl(1-5)",
                "W_auto","W_wiernoÅ›Ä‡","W_jÄ™zyk","W_styl",
                "Progi(%): 5.0","4.5","4.0","3.5","3.0",
                "Wynik_finalny_%","Ocena"
            ]
        )

def grade_from_thresholds(pct: float, th_5, th_45, th_40, th_35, th_30) -> str:
    if pct >= th_5:  return "5.0"
    if pct >= th_45: return "4.5"
    if pct >= th_40: return "4.0"
    if pct >= th_35: return "3.5"
    if pct >= th_30: return "3.0"
    return "2.0"

def gs_get_client_from_secrets():
    sa_info = st.secrets.get("gcp_service_account", None)
    sheet_id = st.secrets.get("sheet_id", None)
    if not sa_info or not sheet_id:
        return None, None
    scopes = ["https://www.googleapis.com/auth/spreadsheets"]
    creds = Credentials.from_service_account_info(sa_info, scopes=scopes)
    client = gspread.authorize(creds)
    return client, sheet_id

def gs_append_row(row_list: list):
    client, sheet_id = gs_get_client_from_secrets()
    if not client or not sheet_id:
        raise RuntimeError("Brak konfiguracji Google Sheets w st.secrets.")
    sh = client.open_by_key(sheet_id)
    ws = sh.sheet1
    ws.append_row(row_list, value_input_option="USER_ENTERED")

# ---------- KOMENTARZE SZABLONOWE (per sekcja) ----------
SECTION_TEMPLATES = {
    "auto": {
        "name": "Analiza automatyczna (Similarity)",
        "ranges": [
            (90, "Bardzo wysoka zgodnoÅ›Ä‡ znaczeniowa z wzorcami. Parafrazy trafne i adekwatne do kontekstu."),
            (80, "Wysoka zgodnoÅ›Ä‡; drobne rÃ³Å¼nice w ujÄ™ciu treÅ›ci, ale sens zachowany."),
            (70, "Umiarkowana zgodnoÅ›Ä‡; czÄ™Å›Ä‡ fragmentÃ³w parafrazowana z przesuniÄ™ciem sensu."),
            (60, "Niska zgodnoÅ›Ä‡; sprawdÅº, czy wszystkie informacje ÅºrÃ³dÅ‚a zostaÅ‚y zachowane."),
            (0,  "Bardzo niska zgodnoÅ›Ä‡; przeanalizuj segment po segmencie wzglÄ™dem ÅºrÃ³dÅ‚a i wzorcÃ³w.")
        ],
    },
    "faith": {
        "name": "WiernoÅ›Ä‡",
        "ranges": [
            (90, "WiernoÅ›Ä‡ bardzo dobra â€” brak istotnych pominiÄ™Ä‡ i nadinterpretacji."),
            (80, "Generalnie wierne; drobne skrÃ³ty lub uogÃ³lnienia."),
            (70, "CzÄ™Å›ciowo wierne; doprecyzuj szczegÃ³Å‚y i terminy kluczowe."),
            (60, "Niska wiernoÅ›Ä‡; czÄ™Å›Ä‡ treÅ›ci zmieniona lub pominiÄ™ta."),
            (0,  "WiernoÅ›Ä‡ bardzo niska; warto porÃ³wnaÄ‡ zdania 1:1 ze ÅºrÃ³dÅ‚em.")
        ],
    },
    "lang": {
        "name": "PoprawnoÅ›Ä‡ jÄ™zykowa",
        "ranges": [
            (90, "Bardzo dobra poprawnoÅ›Ä‡: gramatyka/skÅ‚adnia bez zarzutu, naturalne kolokacje."),
            (80, "Dobra poprawnoÅ›Ä‡; sporadyczne potkniÄ™cia nie zaburzajÄ… odbioru."),
            (70, "Umiarkowana poprawnoÅ›Ä‡; popraw drobne bÅ‚Ä™dy gramatyczne i kolokacyjne."),
            (60, "Niska poprawnoÅ›Ä‡; widoczne kalki i bÅ‚Ä™dy skÅ‚adniowe."),
            (0,  "Bardzo niska poprawnoÅ›Ä‡; zalecana gruntowna redakcja.")
        ],
    },
    "style": {
        "name": "Styl / naturalnoÅ›Ä‡",
        "ranges": [
            (90, "Styl bardzo naturalny i spÃ³jny z rejestrem."),
            (80, "Styl dobry; miejscami sztywnoÅ›Ä‡ lub dosÅ‚ownoÅ›Ä‡."),
            (70, "Styl umiarkowany; rozwaÅ¼ prostszÄ… skÅ‚adniÄ™ i idiomatyczne frazy."),
            (60, "Styl sÅ‚aby; widoczne kaleki i sztuczne brzmienie."),
            (0,  "Styl bardzo sÅ‚aby; zalecane przeformuÅ‚owanie dla pÅ‚ynnoÅ›ci i rejestru.")
        ],
    },
}

def _comment_from_templates(section_key: str, pct: float) -> str:
    tmpl = SECTION_TEMPLATES[section_key]
    for threshold, text in tmpl["ranges"]:
        if pct >= threshold:
            return f"**{tmpl['name']}** â€” {text}"
    return f"**{tmpl['name']}** â€” (brak szablonu)"

def generate_feedback(sim_pct: float, faith_pct: float, lang_pct: float, style_pct: float) -> str:
    parts = [
        _comment_from_templates("auto",  sim_pct),
        _comment_from_templates("faith", faith_pct),
        _comment_from_templates("lang",  lang_pct),
        _comment_from_templates("style", style_pct),
    ]
    weakest_label, weakest_score = min(
        [("wiernoÅ›Ä‡", faith_pct), ("jÄ™zyk", lang_pct), ("styl", style_pct), ("similarity", sim_pct)],
        key=lambda x: x[1]
    )
    tips = {
        "wiernoÅ›Ä‡": "PorÃ³wnaj tÅ‚umaczenie ze ÅºrÃ³dÅ‚em zdanie po zdaniu; sprawdÅº kompletnoÅ›Ä‡ informacji i terminologiÄ™.",
        "jÄ™zyk": "ZrÃ³b redakcjÄ™ gramatyczno-kolokacyjnÄ…; przeczytaj tekst na gÅ‚os.",
        "styl": "UproÅ›Ä‡ skÅ‚adniÄ™ i wybierz bardziej idiomatyczne frazy; dopasuj rejestr.",
        "similarity": "Zestaw tÅ‚umaczenie z kilkoma wzorcami; doprecyzuj fragmenty o najniÅ¼szym dopasowaniu.",
    }
    summary = f"\n**Podsumowanie:** najmocniej warto popracowaÄ‡ nad: **{weakest_label}**. Sugestia: {tips[weakest_label]}"
    return "\n\n".join(parts) + summary

# ---------- PORÃ“WNANIE ZDAÅƒ ----------
_SENT_SPLIT_RE = re.compile(r'(?<=[\.\?\!])\s+')

def split_sentences(text: str) -> list[str]:
    text = text.strip()
    if not text:
        return []
    if not re.search(r'[.!?]', text):
        return [text]
    parts = _SENT_SPLIT_RE.split(text)
    merged = []
    for p in parts:
        if merged and len(p.strip()) < 2:
            merged[-1] = merged[-1] + " " + p
        else:
            merged.append(p.strip())
    return [s for s in merged if s]

def _best_literal(ss: str, pool_ref_sents: list[str]):
    best_lit, best_lit_ref = 0.0, ""
    for rs in pool_ref_sents:
        sc = difflib.SequenceMatcher(None, ss.lower(), rs.lower()).ratio()
        if sc > best_lit:
            best_lit, best_lit_ref = sc, rs
    return best_lit, best_lit_ref

def _best_semantic(ss: str, pool_ref_sents: list[str]):
    model = load_st_model()
    emb_ss = model.encode(ss, normalize_embeddings=True)
    emb_pool = model.encode(pool_ref_sents, normalize_embeddings=True)
    sims = [float(np.dot(emb_ss, r)) for r in emb_pool]
    k = int(np.argmax(sims))
    return sims[k], pool_ref_sents[k]

def sent_level_alignment_best(student_text: str, refs_list: list[str], use_semantics: bool):
    """Dla kaÅ¼dego zdania studenta: najlepszy wzorzec z caÅ‚ej puli zdaÅ„ referencyjnych."""
    pool_ref_sents = []
    for ref in refs_list:
        for rs in split_sentences(ref):
            if rs.strip():
                pool_ref_sents.append(rs.strip())
    if not pool_ref_sents:
        return []

    stud_sents = split_sentences(student_text)
    rows = []
    for i, ss in enumerate(stud_sents, start=1):
        best_lit, best_lit_ref = _best_literal(ss, pool_ref_sents)
        if use_semantics:
            best_sem, best_sem_ref = _best_semantic(ss, pool_ref_sents)
        else:
            best_sem, best_sem_ref = None, None

        diff_tokens = list(difflib.ndiff(ss.split(), (best_lit_ref or "").split()))
        if len(diff_tokens) > 120:
            diff_tokens = diff_tokens[:120] + ["..."]
        diff_preview = " ".join(diff_tokens)
        shown_ref = best_sem_ref if (use_semantics and best_sem_ref) else best_lit_ref

        rows.append({
            "idx": i,
            "stud": ss,
            "ref": shown_ref,
            "lit": best_lit,        # 0..1
            "sem": best_sem,        # 0..1 lub None
            "diff": diff_preview,
        })
    return rows

def sent_level_alignment_1to1(student_text: str, refs_list: list[str], use_semantics: bool):
    """Parowanie 1:1 wg kolejnoÅ›ci zdaÅ„: zdanie i-te studenta â†” zdanie i-te z pierwszego wzorca."""
    primary_ref = refs_list[0] if refs_list else ""
    stud_sents = split_sentences(student_text)
    ref_sents  = split_sentences(primary_ref)
    n = max(len(stud_sents), len(ref_sents))
    rows = []
    model = load_st_model() if use_semantics else None

    for i in range(1, n+1):
        ss = stud_sents[i-1] if i-1 < len(stud_sents) else ""
        rs = ref_sents[i-1]  if i-1 < len(ref_sents)  else ""

        best_lit = difflib.SequenceMatcher(None, ss.lower(), rs.lower()).ratio() if ss and rs else 0.0
        if use_semantics and ss and rs:
            emb_ss = model.encode(ss, normalize_embeddings=True)
            emb_rs = model.encode(rs, normalize_embeddings=True)
            best_sem = float(np.dot(emb_ss, emb_rs))
        else:
            best_sem = None

        diff_tokens = list(difflib.ndiff(ss.split(), rs.split()))
        if len(diff_tokens) > 120:
            diff_tokens = diff_tokens[:120] + ["..."]
        diff_preview = " ".join(diff_tokens)

        rows.append({
            "idx": i,
            "stud": ss,
            "ref": rs,
            "lit": best_lit,
            "sem": best_sem,
            "diff": diff_preview,
        })
    return rows

def short_hint_for_sentence(lit_pct: float, sem_pct: float) -> str:
    """KrÃ³tka wskazÃ³wka dla zdaÅ„ o niskich wynikach."""
    s = sem_pct if sem_pct is not None else lit_pct
    if s >= 80:
        return "OK â€“ zgodnoÅ›Ä‡ wysoka."
    if s >= 70:
        return "Drobne rozbieÅ¼noÅ›ci â€“ doprecyzuj szczegÃ³Å‚y."
    if s >= 60:
        return "RozwaÅ¼ przeformuÅ‚owanie fragmentu lub sprawdÅº sens wzglÄ™dem ÅºrÃ³dÅ‚a."
    return "Niska zgodnoÅ›Ä‡ â€“ porÃ³wnaj ze ÅºrÃ³dÅ‚em, uproÅ›Ä‡ skÅ‚adniÄ™ i doprecyzuj sÅ‚ownictwo."

# ---------- SIDEBAR ----------
with st.sidebar:
    st.markdown("### âš™ï¸ Instrukcja")
    st.markdown(
        "- Wklej **tekst ÅºrÃ³dÅ‚owy** (opcjonalnie), **tÅ‚umaczenie studenta** i **kilka wzorcÃ³w**.\n"
        "- **KaÅ¼de tÅ‚umaczenie wzorcowe oddziel pustÄ… liniÄ…** (Enter, Enter).\n"
        "- UzupeÅ‚nij **rubrykÄ™** i kliknij **OceÅ„ tÅ‚umaczenie**.\n"
        "- Na dole pobierzesz **CSV**. (Opcjonalnie: zapis do **Google Sheets** w sekcjach App Settings)."
    )
    st.caption("Similarity = miks semantyki i dopasowania literalnego. Wagi i progi ustawisz niÅ¼ej.")
    st.markdown("---")
    st.markdown("#### Google Sheets (opcjonalnie)")
    st.caption("DziaÅ‚a, jeÅ›li skonfigurujesz sekrety w Streamlit Cloud (service account + sheet_id).")
    use_gsheets = st.toggle("WÅ‚Ä…cz zapis do Google Sheets", value=False)

st.title("ğŸ“˜ Ocena tÅ‚umaczeÅ„ studentÃ³w â€” wersja nauczycielska")

# ---------- FORMULARZ ----------
col_left, col_right = st.columns([2, 1])

with col_left:
    st.subheader("Dane wejÅ›ciowe")
    student_name = st.text_input("ğŸ‘¤ ImiÄ™ i nazwisko studenta", "")
    assignment_name = st.text_input("ğŸ—‚ï¸ Nazwa zadania / pliku (opcjonalnie)", "")
    source_text = st.text_area("ğŸ§¾ Tekst ÅºrÃ³dÅ‚owy (dla kontekstu, opcjonalnie)", height=120)
    student_translation = st.text_area("âœï¸ TÅ‚umaczenie studenta", height=180)
    reference_translations = st.text_area(
        "âœ… TÅ‚umaczenia wzorcowe (kaÅ¼de tÅ‚umaczenie oddziel **pustÄ… liniÄ…**)",
        height=200,
        placeholder=("Wklej jedno lub wiÄ™cej poprawnych tÅ‚umaczeÅ„.\n"
                     "KaÅ¼de tÅ‚umaczenie oddziel pustÄ… liniÄ… (Enter, Enter).")
    )

with col_right:
    st.subheader("Rubryka oceny")
    faithfulness = st.slider("WiernoÅ›Ä‡ (1â€“5)", 1, 5, 4)
    language_quality = st.slider("PoprawnoÅ›Ä‡ jÄ™zykowa (1â€“5)", 1, 5, 4)
    style = st.slider("Styl / naturalnoÅ›Ä‡ (1â€“5)", 1, 5, 4)

    st.subheader("Analiza (globalna)")
    use_semantics = st.toggle("UÅ¼yj analizy semantycznej (rekomendowane)", value=True)
    sem_weight_mix = st.slider("Waga semantyki w Similarity", 0.0, 1.0, 0.7, 0.05)

    st.subheader("Wagi komponentÃ³w (do oceny koÅ„cowej)")
    w_auto = st.number_input("Waga: Similarity", min_value=0.0, value=0.40, step=0.05)
    w_faith = st.number_input("Waga: WiernoÅ›Ä‡",   min_value=0.0, value=0.35, step=0.05)
    w_lang  = st.number_input("Waga: JÄ™zyk",      min_value=0.0, value=0.15, step=0.05)
    w_style = st.number_input("Waga: Styl",       min_value=0.0, value=0.10, step=0.05)
    st.caption("Wagi nie muszÄ… sumowaÄ‡ siÄ™ do 1 â€” znormalizujemy je automatycznie.")

# ---------- SKALA OCEN ----------
st.markdown("### ğŸ§® Skala ocen (progi % â†’ ocena PL)")
cols = st.columns(5)
with cols[0]: th_5  = st.number_input("5.0 od (%)", 0.0, 100.0, 90.0, 1.0)
with cols[1]: th_45 = st.number_input("4.5 od (%)", 0.0, 100.0, 80.0, 1.0)
with cols[2]: th_40 = st.number_input("4.0 od (%)", 0.0, 100.0, 70.0, 1.0)
with cols[3]: th_35 = st.number_input("3.5 od (%)", 0.0, 100.0, 60.0, 1.0)
with cols[4]: th_30 = st.number_input("3.0 od (%)", 0.0, 100.0, 50.0, 1.0)
st.caption("Upewnij siÄ™, Å¼e progi malejÄ…: 5.0 â‰¥ 4.5 â‰¥ 4.0 â‰¥ 3.5 â‰¥ 3.0")

# ---------- PRZYCISK ----------
if st.button("ğŸ” OceÅ„ tÅ‚umaczenie", type="primary"):
    if not student_translation.strip():
        st.error("WprowadÅº tÅ‚umaczenie studenta.")
    elif not reference_translations.strip():
        st.error("WprowadÅº co najmniej jedno tÅ‚umaczenie wzorcowe.")
    else:
        # Lista wzorcÃ³w (puste linie rozdzielajÄ… tÅ‚umaczenia)
        raw = reference_translations.replace("\r\n", "\n")
        refs_list = [blk.strip() for blk in raw.split("\n\n") if blk.strip()]
        if len(refs_list) == 1 and "\n" in refs_list[0]:
            refs_list = [r.strip() for r in raw.split("\n") if r.strip()]

        # PodobieÅ„stwo globalne
        lit_sim, lit_best_ref, diff_preview = compute_best_match(student_translation, refs_list)
        if use_semantics:
            sem_sim, sem_best_ref = best_semantic_match(student_translation, refs_list)
        else:
            sem_sim, sem_best_ref = None, None
        display_best_ref = sem_best_ref if (use_semantics and sem_best_ref) else lit_best_ref
        combined_similarity = (sem_weight_mix * sem_sim + (1 - sem_weight_mix) * lit_sim) if use_semantics else lit_sim

        # Prezentacja metryk globalnych
        st.success("Analiza zakoÅ„czona.")
        st.markdown("#### NajbliÅ¼sze tÅ‚umaczenie wzorcowe")
        st.write(display_best_ref if display_best_ref else "â€”")
        m1, m2, m3 = st.columns(3)
        with m1: st.metric("PodobieÅ„stwo (literalne)", f"{lit_sim:.0%}")
        with m2: st.metric("PodobieÅ„stwo (semantyczne)", "â€”" if sem_sim is None else f"{sem_sim:.0%}")
        with m3: st.metric("Similarity (Å‚Ä…czna)", f"{combined_similarity:.0%}")
        with st.expander("PodglÄ…d rÃ³Å¼nic (skrÃ³t â€“ wobec wzorca literalnego)"):
            st.code(diff_preview)

        # ---------- PANEL PORÃ“WNANIA ZDAÅƒ ----------
        st.markdown("### ğŸ” PorÃ³wnanie zdaÅ„ (zdanie-za-zdaniem)")
        mode_col, thr_col, chk_col = st.columns([1.2, 1, 1])
        with mode_col:
            sent_mode = st.radio(
                "Tryb dopasowania zdaÅ„",
                options=["Najlepsze dopasowanie", "1:1 alignment"],
                help="â€˜Najlepszeâ€™ wybiera dla kaÅ¼dego zdania studenta najlepiej pasujÄ…ce zdanie z caÅ‚ej puli wzorcÃ³w.\nâ€˜1:1â€™ Å‚Ä…czy zdanie i-te studenta ze zdaniem i-tym pierwszego wzorca."
            )
        with thr_col:
            low_thr = st.slider("PrÃ³g filtrowania (%)", 0, 100, 70, 5, help="PokaÅ¼ tylko zdania poniÅ¼ej tego progu.")
        with chk_col:
            show_only_low = st.checkbox("PokaÅ¼ tylko poniÅ¼ej progu", value=True)

        # Oblicz wiersze porÃ³wnaÅ„
        if sent_mode == "1:1 alignment":
            rows = sent_level_alignment_1to1(student_translation, refs_list, use_semantics)
        else:
            rows = sent_level_alignment_best(student_translation, refs_list, use_semantics)

        # Zbuduj tabelÄ™ + kolorowanie i komentarze per zdanie
        table_rows = []
        for r in rows:
            lit_pct = int(round(r["lit"] * 100)) if r["lit"] is not None else None
            sem_pct = int(round(r["sem"] * 100)) if r["sem"] is not None else None
            shown = sem_pct if sem_pct is not None else lit_pct
            if show_only_low and shown is not None and shown >= low_thr:
                continue
            hint = short_hint_for_sentence(lit_pct if lit_pct is not None else 0,
                                           sem_pct if sem_pct is not None else None)
            table_rows.append({
                "Zdanie #": r["idx"],
                "Zdanie studenta": r["stud"],
                "Najlepszy wzorzec (zdanie)" if sent_mode!="1:1 alignment" else "Wzorzec (1:1)": r["ref"],
                "Literalnie (%)": lit_pct,
                "Semantycznie (%)": sem_pct if sem_pct is not None else "",
                "RÃ³Å¼nice (skrÃ³t)": r["diff"],
                "WskazÃ³wka": hint,
            })

        if not table_rows:
            st.info("Brak zdaÅ„ do wyÅ›wietlenia przy wybranych filtrach/trybie.")
        else:
            df_sent = pd.DataFrame(table_rows)

            # Funkcja kolorujÄ…ca komÃ³rki wg progÃ³w
            def color_thresholds(val):
                if val == "" or pd.isna(val):
                    return ""
                try:
                    v = float(val)
                except:
                    return ""
                if v >= 80:
                    return "background-color: #e6ffe6"  # zielonkawe
                if v >= 60:
                    return "background-color: #fff9cc"  # Å¼Ã³Å‚tawe
                return "background-color: #ffe6e6"      # czerwonawe

            # Styler â€“ kolorujemy dwie kolumny procentowe
            styled = df_sent.style.applymap(color_thresholds, subset=["Literalnie (%)", "Semantycznie (%)"])
            st.dataframe(styled, use_container_width=True)

        # ---------- HINTY OGÃ“LNE (miÄ™kkie) ----------
        issues = []
        text_lower = student_translation.lower()
        refs_joined_lower = " ".join(refs_list).lower()
        if "since" in text_lower and "for" in refs_joined_lower:
            issues.append("MoÅ¼liwe naduÅ¼ycie 'since' dla okresu czasu â€“ rozwaÅ¼ 'for'.")
        if "make a photo" in text_lower:
            issues.append("Kolokacja: zwykle 'take a photo', nie 'make a photo'.")
        if "i have" in text_lower and "years old" in text_lower:
            issues.append("Kalka: 'I am X years old', nie 'I have X years old'.")
        if issues:
            st.markdown("#### Potencjalne kwestie do sprawdzenia (ogÃ³lne)")
            for it in issues:
                st.write(f"- {it}")

        # ---------- OCENA KOÅƒCOWA ----------
        # Wagi â†’ normalizacja
        w_sum = max(w_auto + w_faith + w_lang + w_style, 1e-9)
        wn_auto, wn_faith, wn_lang, wn_style = w_auto/w_sum, w_faith/w_sum, w_lang/w_sum, w_style/w_sum
        # Skale (0..1)
        faith_norm = faithfulness / 5.0
        lang_norm  = language_quality / 5.0
        style_norm = style / 5.0
        final_0_1 = wn_auto * combined_similarity + wn_faith * faith_norm + wn_lang * lang_norm + wn_style * style_norm
        final_pct = float(final_0_1 * 100.0)
        final_grade = grade_from_thresholds(final_pct, th_5, th_45, th_40, th_35, th_30)

        # Komentarz Å‚Ä…czny zaleÅ¼ny od % w sekcjach
        sim_pct = combined_similarity * 100.0
        faith_pct = faith_norm * 100.0
        lang_pct  = lang_norm  * 100.0
        style_pct = style_norm * 100.0
        auto_fb = generate_feedback(sim_pct, faith_pct, lang_pct, style_pct)

        st.markdown("#### Ocena koÅ„cowa")
        g1, g2 = st.columns(2)
        with g1: st.metric("Wynik finalny ( % )", f"{final_pct:.0f}%")
        with g2: st.metric("Ocena (PL)", final_grade)

        st.markdown("#### Komentarz dla studenta")
        lead = "Åšwietny wynik." if final_pct >= 90 else "Dobry wynik." if final_pct >= 80 else \
               "Åšredni wynik." if final_pct >= 70 else "Wymaga pracy." if final_pct >= 60 else "Do gruntownej poprawy."
        teacher_comment = st.text_area("Uwagi prowadzÄ…cej (opcjonalnie)", height=100)
        final_comment = auto_fb if not teacher_comment.strip() else f"{auto_fb}\n\n**Uwagi prowadzÄ…cej:**\n{teacher_comment.strip()}"
        st.write(f"**{lead}**")
        st.write(final_comment)

        # ---------- ZAPIS WYNIKU DO TABELI (SESJA) ----------
        ensure_results_df()
        new_row = {
            "Data": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "Student": student_name or "â€”",
            "Zadanie/Plik": assignment_name or "â€”",
            "PodobieÅ„stwo_literalne": round(lit_sim, 3),
            "PodobieÅ„stwo_semantyczne": None if sem_sim is None else round(sem_sim, 3),
            "Wynik_Å‚Ä…czny": round(combined_similarity, 3),
            "WiernoÅ›Ä‡(1-5)": faithfulness, "JÄ™zyk(1-5)": language_quality, "Styl(1-5)": style,
            "W_auto": w_auto, "W_wiernoÅ›Ä‡": w_faith, "W_jÄ™zyk": w_lang, "W_styl": w_style,
            "Progi(%): 5.0": th_5, "4.5": th_45, "4.0": th_40, "3.5": th_35, "3.0": th_30,
            "Wynik_finalny_%": round(final_pct, 1), "Ocena": final_grade,
        }
        st.session_state.results_df = pd.concat(
            [st.session_state.get("results_df", pd.DataFrame(columns=list(new_row.keys()))),
             pd.DataFrame([new_row])],
            ignore_index=True
        )

        # (Opcjonalnie) Zapis do Google Sheets
        if use_gsheets:
            if not GS_AVAILABLE:
                st.warning("Brak bibliotek Google Sheets. SprawdÅº requirements.txt (gspread, google-auth).")
            else:
                try:
                    row_for_gs = [
                        new_row["Data"], new_row["Student"], new_row["Zadanie/Plik"],
                        new_row["PodobieÅ„stwo_literalne"], new_row["PodobieÅ„stwo_semantyczne"], new_row["Wynik_Å‚Ä…czny"],
                        new_row["WiernoÅ›Ä‡(1-5)"], new_row["JÄ™zyk(1-5)"], new_row["Styl(1-5)"],
                        new_row["W_auto"], new_row["W_wiernoÅ›Ä‡"], new_row["W_jÄ™zyk"], new_row["W_styl"],
                        new_row["Progi(%): 5.0"], new_row["4.5"], new_row["4.0"], new_row["3.5"], new_row["3.0"],
                        new_row["Wynik_finalny_%"], new_row["Ocena"],
                    ]
                    gs_append_row(row_for_gs)
                    st.success("Zapisano wiersz do Google Sheets âœ…")
                except Exception as e:
                    st.warning(f"Nie udaÅ‚o siÄ™ zapisaÄ‡ do Google Sheets: {e}")

# ---------- WYNIKI ZBIORCZE ----------
ensure_results_df()
st.markdown("---")
st.subheader("ğŸ“Š Zebrane wyniki (sesja)")

df = st.session_state.results_df.copy()

def _pct_col(series):
    return series.apply(lambda x: "" if pd.isna(x) else f"{float(x)*100:.0f}%")

if not df.empty:
    if "PodobieÅ„stwo_literalne" in df:   df["PodobieÅ„stwo_literalne"] = _pct_col(df["PodobieÅ„stwo_literalne"])
    if "PodobieÅ„stwo_semantyczne" in df: df["PodobieÅ„stwo_semantyczne"] = df["PodobieÅ„stwo_semantyczne"].apply(
        lambda x: "" if pd.isna(x) else f"{float(x)*100:.0f}%"
    )
    if "Wynik_Å‚Ä…czny" in df:             df["Wynik_Å‚Ä…czny"] = _pct_col(df["Wynik_Å‚Ä…czny"])
    if "Wynik_finalny_%" in df:
        df["Wynik_finalny_%"] = df["Wynik_finalny_%"].apply(lambda x: "" if pd.isna(x) else f"{float(x):.0f}%")

st.dataframe(df, use_container_width=True)

if not st.session_state.results_df.empty:
    mean_pct = st.session_state.results_df["Wynik_finalny_%"].astype(float).mean()
    def _grade_to_float(g):
        try: return float(g)
        except: return np.nan
    mean_grade = st.session_state.results_df["Ocena"].apply(_grade_to_float).mean()

    st.markdown("### ğŸ“ˆ Åšrednie (sesja)")
    c1, c2 = st.columns(2)
    with c1: st.metric("Åšredni wynik ( % )", f"{mean_pct:.0f}%")
    with c2: st.metric("Åšrednia ocena (PL)", f"{mean_grade:.1f}")

# Pobieranie CSV
csv_data = st.session_state.results_df.to_csv(index=False).encode("utf-8")
st.download_button("â¬‡ï¸ Pobierz wyniki jako CSV", data=csv_data, file_name="wyniki_tlumaczen.csv", mime="text/csv")
