import streamlit as st
import difflib
import pandas as pd
import numpy as np
import re
from datetime import datetime
from sentence_transformers import SentenceTransformer

# (Opcjonalnie) Google Sheets
try:
    import gspread
    from google.oauth2.service_account import Credentials
    GS_AVAILABLE = True
except Exception:
    GS_AVAILABLE = False

# ---------- USTAWIENIA STRONY ----------
st.set_page_config(page_title="Ocena tÅ‚umaczeÅ„ â€“ wersja nauczycielska (dwujÄ™zyczna)", layout="wide")

# ---------- INICJALIZACJA STANU (PAMIÄ˜Ä† UI) ----------
def _init_state():
    ss = st.session_state
    # Panel zdaÅ„ â€“ pamiÄ™Ä‡
    ss.setdefault("sent_mode", "Najlepsze dopasowanie")  # albo "1:1 alignment"
    ss.setdefault("low_thr", 70)                         # prÃ³g filtrowania zdaÅ„ (%)
    ss.setdefault("show_only_low", True)
    # Ostatnie dane do panelu zdaÅ„
    ss.setdefault("last_student_translation", "")
    ss.setdefault("last_refs_list", [])
    ss.setdefault("last_use_semantics", True)
    ss.setdefault("last_analysis_mode", "DwujÄ™zyczny (Å¹rÃ³dÅ‚o â†” Student)")
    ss.setdefault("last_source_text", "")
    # Tabela wynikÃ³w
    if "results_df" not in ss:
        ss.results_df = pd.DataFrame(
            columns=[
                "Data","Student","Zadanie/Plik",
                "Tryb","PodobieÅ„stwo_crossling","PodobieÅ„stwo_wzorcowe","Wynik_Å‚Ä…czny",
                "WiernoÅ›Ä‡(1-5)","JÄ™zyk(1-5)","Styl(1-5)",
                "W_auto","W_wiernoÅ›Ä‡","W_jÄ™zyk","W_styl",
                "Mix(Å¹rÃ³dÅ‚oâ†”Wzorce)","Progi(%): 5.0","4.5","4.0","3.5","3.0",
                "Wynik_finalny_%","Ocena"
            ]
        )

_init_state()

# ---------- MODEL SEMANTYCZNY (wielojÄ™zyczny) ----------
@st.cache_resource
def load_st_model():
    # Model wielojÄ™zyczny do PLâ†”EN (sprawdza siÄ™ takÅ¼e dla ENâ†”EN / PLâ†”PL)
    return SentenceTransformer("sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2")

# ---------- POMOCNICZE: podobieÅ„stwa globalne ----------
def cosine_sim(a, b):
    return float(np.dot(a, b))

def embed_texts(texts: list[str]):
    model = load_st_model()
    return model.encode(texts, normalize_embeddings=True)

def crossling_global_similarity(source_text: str, student_text: str) -> float:
    """Semantyczne podobieÅ„stwo miÄ™dzyjÄ™zykowe ÅºrÃ³dÅ‚oâ†”tÅ‚umaczenie studenta (0..1)."""
    if not source_text.strip() or not student_text.strip():
        return 0.0
    a, b = embed_texts([source_text, student_text])
    return cosine_sim(a, b)

def best_ref_global_similarity(student_text: str, refs: list[str]) -> tuple[float,str]:
    """Najlepsze semantyczne dopasowanie studentâ†”wzorce (0..1, ref_text)."""
    if not refs:
        return 0.0, ""
    model = load_st_model()
    emb_s = model.encode(student_text, normalize_embeddings=True)
    emb_r = model.encode(refs, normalize_embeddings=True)
    sims = [float(np.dot(emb_s, r)) for r in emb_r]
    k = int(np.argmax(sims))
    return sims[k], refs[k]

def best_literal_match(student_text: str, refs: list[str]):
    """Literalne dopasowanie (uÅ¼ywamy tylko informacyjnie)."""
    best_ref, best_score = "", 0.0
    for ref in refs:
        score = difflib.SequenceMatcher(None, student_text.lower(), ref.lower()).ratio()
        if score > best_score:
            best_score, best_ref = score, ref
    return best_score, best_ref

# ---------- KOMENTARZE SZABLONOWE ----------
SECTION_TEMPLATES = {
    "auto": {
        "name": "Analiza automatyczna (Similarity)",
        "ranges": [
            (90, "Bardzo wysoka zgodnoÅ›Ä‡ znaczeniowa. Parafrazy trafne i adekwatne do kontekstu."),
            (80, "Wysoka zgodnoÅ›Ä‡; drobne rÃ³Å¼nice w ujÄ™ciu treÅ›ci, ale sens zachowany."),
            (70, "Umiarkowana zgodnoÅ›Ä‡; miejscami przesuniÄ™cie sensu."),
            (60, "Niska zgodnoÅ›Ä‡; sprawdÅº kompletnoÅ›Ä‡ informacji wzglÄ™dem ÅºrÃ³dÅ‚a/wzorcÃ³w."),
            (0,  "Bardzo niska zgodnoÅ›Ä‡; przeanalizuj segment po segmencie.")
        ],
    },
    "faith": {
        "name": "WiernoÅ›Ä‡",
        "ranges": [
            (90, "WiernoÅ›Ä‡ bardzo dobra â€” brak istotnych pominiÄ™Ä‡ i nadinterpretacji."),
            (80, "Generalnie wierne; drobne skrÃ³ty lub uogÃ³lnienia."),
            (70, "CzÄ™Å›ciowo wierne; doprecyzuj szczegÃ³Å‚y i terminy kluczowe."),
            (60, "Niska wiernoÅ›Ä‡; czÄ™Å›Ä‡ treÅ›ci zmieniona lub pominiÄ™ta."),
            (0,  "WiernoÅ›Ä‡ bardzo niska; porÃ³wnaj zdania 1:1 ze ÅºrÃ³dÅ‚em.")
        ],
    },
    "lang": {
        "name": "PoprawnoÅ›Ä‡ jÄ™zykowa",
        "ranges": [
            (90, "Bardzo dobra poprawnoÅ›Ä‡: gramatyka/skÅ‚adnia bez zarzutu, naturalne kolokacje."),
            (80, "Dobra poprawnoÅ›Ä‡; sporadyczne potkniÄ™cia nie zaburzajÄ… odbioru."),
            (70, "Umiarkowana poprawnoÅ›Ä‡; popraw drobne bÅ‚Ä™dy gramatyczne i kolokacyjne."),
            (60, "Niska poprawnoÅ›Ä‡; widoczne kalki i bÅ‚Ä™dy skÅ‚adniowe."),
            (0,  "Bardzo niska poprawnoÅ›Ä‡; zalecana gruntowna redakcja.")
        ],
    },
    "style": {
        "name": "Styl / naturalnoÅ›Ä‡",
        "ranges": [
            (90, "Styl bardzo naturalny i spÃ³jny z rejestrem."),
            (80, "Styl dobry; miejscami sztywnoÅ›Ä‡ lub dosÅ‚ownoÅ›Ä‡."),
            (70, "Styl umiarkowany; uproÅ›Ä‡ skÅ‚adniÄ™ i stosuj idiomatyczne frazy."),
            (60, "Styl sÅ‚aby; widoczne kaleki i sztuczne brzmienie."),
            (0,  "Styl bardzo sÅ‚aby; przeformuÅ‚uj dla pÅ‚ynnoÅ›ci i rejestru.")
        ],
    },
}

def _comment_from_templates(section_key: str, pct: float) -> str:
    tmpl = SECTION_TEMPLATES[section_key]
    for threshold, text in tmpl["ranges"]:
        if pct >= threshold:
            return f"**{tmpl['name']}** â€” {text}"
    return f"**{tmpl['name']}** â€” (brak szablonu)"

def generate_feedback(sim_pct: float, faith_pct: float, lang_pct: float, style_pct: float) -> str:
    parts = [
        _comment_from_templates("auto",  sim_pct),
        _comment_from_templates("faith", faith_pct),
        _comment_from_templates("lang",  lang_pct),
        _comment_from_templates("style", style_pct),
    ]
    weakest_label, _ = min(
        [("wiernoÅ›Ä‡", faith_pct), ("jÄ™zyk", lang_pct), ("styl", style_pct), ("similarity", sim_pct)],
        key=lambda x: x[1]
    )
    tips = {
        "wiernoÅ›Ä‡": "PorÃ³wnaj tÅ‚umaczenie ze ÅºrÃ³dÅ‚em zdanie po zdaniu; sprawdÅº kompletnoÅ›Ä‡ i terminologiÄ™.",
        "jÄ™zyk": "Redakcja gramatyczno-kolokacyjna; przeczytaj tekst na gÅ‚os.",
        "styl": "UproÅ›Ä‡ skÅ‚adniÄ™ i stosuj idiomatyczne frazy; dopasuj rejestr.",
        "similarity": "Skup siÄ™ na zdaniach o najniÅ¼szym dopasowaniu (panel poniÅ¼ej).",
    }
    summary = f"\n**Podsumowanie:** najsÅ‚abszy aspekt: **{weakest_label}**. Sugestia: {tips[weakest_label]}"
    return "\n\n".join(parts) + summary

# ---------- PORÃ“WNANIE ZDAÅƒ ----------
_SENT_SPLIT_RE = re.compile(r'(?<=[\.\?\!])\s+')

def split_sentences(text: str) -> list[str]:
    text = text.strip()
    if not text:
        return []
    if not re.search(r'[.!?]', text):
        return [text]
    parts = _SENT_SPLIT_RE.split(text)
    merged = []
    for p in parts:
        if merged and len(p.strip()) < 2:
            merged[-1] = merged[-1] + " " + p
        else:
            merged.append(p.strip())
    return [s for s in merged if s]

def sent_align_best(student_text: str, pool_ref_sents: list[str], use_semantics: bool, bilingual: bool):
    """Najlepsze dopasowanie zdaÅ„: gdy bilingual=True â€“ pool_ref_sents to zdania Å¹RÃ“DÅOWE."""
    if not pool_ref_sents:
        return []
    stud_sents = split_sentences(student_text)
    model = load_st_model() if (use_semantics or bilingual) else None
    rows = []
    # Pre-embed pool dla szybkoÅ›ci
    emb_pool = model.encode(pool_ref_sents, normalize_embeddings=True) if (model and (use_semantics or bilingual)) else None

    for i, ss in enumerate(stud_sents, start=1):
        # LiteralnoÅ›Ä‡ sensowna tylko gdy ten sam jÄ™zyk (czyli tryb wzorcowy)
        best_lit, best_lit_ref = 0.0, ""
        if not bilingual:
            for rs in pool_ref_sents:
                sc = difflib.SequenceMatcher(None, ss.lower(), rs.lower()).ratio()
                if sc > best_lit:
                    best_lit, best_lit_ref = sc, rs

        # Semantyka â€“ dziaÅ‚a w obu trybach (wielojÄ™zycznie)
        if model and emb_pool is not None and ss.strip():
            emb_ss = model.encode(ss, normalize_embeddings=True)
            sims = [float(np.dot(emb_ss, r)) for r in emb_pool]
            k = int(np.argmax(sims))
            best_sem, best_sem_ref = sims[k], pool_ref_sents[k]
        else:
            best_sem, best_sem_ref = None, None

        # Diff podglÄ…d â€“ sensowniejszy literalnie (gdy nie bilingual)
        if not bilingual:
            base_ref_for_diff = best_lit_ref or ""
            diff_tokens = list(difflib.ndiff(ss.split(), base_ref_for_diff.split()))
            if len(diff_tokens) > 120:
                diff_tokens = diff_tokens[:120] + ["..."]
            diff_preview = " ".join(diff_tokens)
        else:
            diff_preview = "(porÃ³wnanie miÄ™dzyjÄ™zykowe â€“ diff literalny pominiÄ™ty)"

        shown_ref = best_sem_ref if (best_sem_ref) else best_lit_ref
        rows.append({
            "idx": i,
            "stud": ss,
            "ref": shown_ref,
            "lit": None if bilingual else best_lit,
            "sem": best_sem,
            "diff": diff_preview,
        })
    return rows

def sent_align_1to1(student_text: str, ref_text: str, use_semantics: bool, bilingual: bool):
    """1:1: i-te zdanie studenta â†” i-te zdanie z ref_text (ÅºrÃ³dÅ‚o lub gÅ‚Ã³wny wzorzec)."""
    stud_sents = split_sentences(student_text)
    ref_sents  = split_sentences(ref_text)
    n = max(len(stud_sents), len(ref_sents))
    model = load_st_model() if (use_semantics or bilingual) else None
    rows = []
    for i in range(1, n+1):
        ss = stud_sents[i-1] if i-1 < len(stud_sents) else ""
        rs = ref_sents[i-1]  if i-1 < len(ref_sents)  else ""
        # literalnoÅ›Ä‡ tylko w trybie wzorcowym
        best_lit = None if bilingual else (difflib.SequenceMatcher(None, ss.lower(), rs.lower()).ratio() if ss and rs else 0.0)
        if model and ss and rs:
            emb_ss = model.encode(ss, normalize_embeddings=True)
            emb_rs = model.encode(rs, normalize_embeddings=True)
            best_sem = float(np.dot(emb_ss, emb_rs))
        else:
            best_sem = None
        if not bilingual:
            diff_tokens = list(difflib.ndiff(ss.split(), rs.split()))
            if len(diff_tokens) > 120:
                diff_tokens = diff_tokens[:120] + ["..."]
            diff_preview = " ".join(diff_tokens)
        else:
            diff_preview = "(porÃ³wnanie miÄ™dzyjÄ™zykowe â€“ diff literalny pominiÄ™ty)"
        rows.append({"idx": i, "stud": ss, "ref": rs, "lit": best_lit, "sem": best_sem, "diff": diff_preview})
    return rows

def short_hint_for_sentence(lit_pct: float|None, sem_pct: float|None, bilingual: bool) -> str:
    s = sem_pct if sem_pct is not None else (lit_pct if lit_pct is not None else 0)
    if s >= 80: return "OK â€“ zgodnoÅ›Ä‡ wysoka."
    if s >= 70: return "Drobne rozbieÅ¼noÅ›ci â€“ doprecyzuj szczegÃ³Å‚y."
    if s >= 60: return "SprawdÅº sens wzglÄ™dem odniesienia; rozwaÅ¼ przeformuÅ‚owanie."
    return "Niska zgodnoÅ›Ä‡ â€“ porÃ³wnaj ze ÅºrÃ³dÅ‚em/wzorcem, uproÅ›Ä‡ skÅ‚adniÄ™ i doprecyzuj sÅ‚ownictwo."
    def extract_low_similarity_examples(student_text: str,
                                    analysis_mode: str,
                                    source_text: str,
                                    refs_list: list[str],
                                    use_semantics: bool,
                                    max_examples: int = 3,
                                    threshold_pct: int = 70):
    """
    Zwraca listÄ™ maks. N przykÅ‚adÃ³w o najniÅ¼szej zgodnoÅ›ci:
    [{idx, stud, ref_or_src, score_pct, hint, diff} ...]
    """
    bilingual = analysis_mode.startswith("DwujÄ™zyczny")
    # Z czego robimy "pool odniesienia"
    if bilingual:
        pool = split_sentences(source_text)
        ref_label = "Å¹rÃ³dÅ‚o"
        ref_text_for_1to1 = source_text
    else:
        # Å‚Ä…czymy wszystkie zdania z wielu wzorcÃ³w
        pool = []
        for r in refs_list:
            pool += split_sentences(r)
        ref_label = "Wzorzec"
        ref_text_for_1to1 = refs_list[0] if refs_list else ""

    if not pool:
        return []

    # Najlepsze dopasowanie zdaÅ„ (per zdanie studenta)
    rows = sent_align_best(student_text, pool, use_semantics=use_semantics, bilingual=bilingual)

    # Dla rankingu bierzemy semantykÄ™, a jeÅ›li jej brak (nie powinniÅ›my), to literalnoÅ›Ä‡
    def best_score(row):
        if row["sem"] is not None:
            return float(row["sem"]) * 100.0
        if row["lit"] is not None:
            return float(row["lit"]) * 100.0
        return 0.0

    # Posortuj rosnÄ…co i odfiltruj tylko < threshold_pct
    rows_sorted = sorted(rows, key=best_score)
    low_rows = [r for r in rows_sorted if best_score(r) < threshold_pct]

    examples = []
    for r in low_rows[:max_examples]:
        score = int(round(best_score(r)))
        hint = short_hint_for_sentence(
            None if r["lit"] is None else int(round(r["lit"] * 100)),
            None if r["sem"] is None else int(round(r["sem"] * 100)),
            bilingual=bilingual
        )
        examples.append({
            "idx": r["idx"],
            "stud": r["stud"],
            "ref_or_src": r["ref"],
            "score_pct": score,
            "hint": hint,
            "diff": r["diff"]
        })
    return examples, ref_label

# ---------- SIDEBAR ----------
with st.sidebar:
    st.markdown("### âš™ï¸ Instrukcja")
    st.markdown(
        "- Wklej **tekst ÅºrÃ³dÅ‚owy** (PL/EN), **tÅ‚umaczenie studenta**.\n"
        "- (Opcjonalnie) w trybie dwujÄ™zycznym moÅ¼esz **doÅ‚Ä…czyÄ‡ wzorce** i ustawiÄ‡ miks.\n"
        "- UzupeÅ‚nij **rubrykÄ™** i kliknij **OceÅ„ tÅ‚umaczenie**.\n"
        "- Panel zdaÅ„ dziaÅ‚a na **ostatnio ocenionych** tekstach."
    )
    st.markdown("---")
    st.markdown("#### Zapisywanie wynikÃ³w")
    overwrite_mode = st.toggle("Nadpisuj istniejÄ…cy wpis (Student+Zadanie)", value=True)
    st.markdown("#### Google Sheets (opcjonalnie)")
    st.caption("DziaÅ‚a, jeÅ›li skonfigurujesz sekrety w Streamlit Cloud (service account + sheet_id).")
    use_gsheets = st.toggle("WÅ‚Ä…cz zapis do Google Sheets", value=False)

st.title("ğŸ“˜ Ocena tÅ‚umaczeÅ„ â€” tryb dwujÄ™zyczny i wzorcowy")

# ---------- TRYB ANALIZY ----------
analysis_mode = st.radio(
    "Tryb analizy",
    options=["DwujÄ™zyczny (Å¹rÃ³dÅ‚o â†” Student)", "Wzorcowy (Student â†” Wzorce)"],
    index=0,
    help="DwujÄ™zyczny: porÃ³wnanie ÅºrÃ³dÅ‚oâ†”student (PLâ†”EN). Wzorcowy: studentâ†”tÅ‚umaczenia wzorcowe."
)

# ---------- FORMULARZ ----------
col_left, col_right = st.columns([2, 1])

with col_left:
    st.subheader("Dane wejÅ›ciowe")
    student_name = st.text_input("ğŸ‘¤ ImiÄ™ i nazwisko studenta", "")
    assignment_name = st.text_input("ğŸ—‚ï¸ Nazwa zadania / pliku (opcjonalnie)", "")
    source_text = st.text_area("ğŸ§¾ Tekst ÅºrÃ³dÅ‚owy (PL/EN)", height=120)
    student_translation = st.text_area("âœï¸ TÅ‚umaczenie studenta (PL/EN)", height=180)

    # Wzorce â€“ zawsze dostÄ™pne, ale mogÄ… byÄ‡ pomijane
    reference_translations = st.text_area(
        "âœ… TÅ‚umaczenia wzorcowe (opcjonalnie, kaÅ¼de tÅ‚umaczenie oddziel **pustÄ… liniÄ…**)",
        height=180,
        placeholder=("Wklej 0, 1 lub wiÄ™cej poprawnych tÅ‚umaczeÅ„.\n"
                     "KaÅ¼de tÅ‚umaczenie oddziel pustÄ… liniÄ… (Enter, Enter).")
    )

with col_right:
    st.subheader("Rubryka oceny")
    faithfulness = st.slider("WiernoÅ›Ä‡ (1â€“5)", 1, 5, 4)
    language_quality = st.slider("PoprawnoÅ›Ä‡ jÄ™zykowa (1â€“5)", 1, 5, 4)
    style = st.slider("Styl / naturalnoÅ›Ä‡ (1â€“5)", 1, 5, 4)

    st.subheader("Analiza automatyczna")
    use_semantics = st.toggle("UÅ¼yj analizy semantycznej (rekomendowane)", value=True)

    # Miks tylko w dwujÄ™zycznym, jeÅ›li uÅ¼ytkownik chce uwzglÄ™dniÄ‡ wzorce
    include_refs_in_bilingual = False
    mix_src_refs = 1.0
    if analysis_mode == "DwujÄ™zyczny (Å¹rÃ³dÅ‚o â†” Student)":
        include_refs_in_bilingual = st.checkbox("UwzglÄ™dnij wzorce dodatkowo (studentâ†”wzorce)", value=False,
                                                help="JeÅ›li zaznaczysz i podasz wzorce, Similarity bÄ™dzie mieszankÄ…: Å¹rÃ³dÅ‚oâ†”Student oraz Studentâ†”Wzorce.")
        if include_refs_in_bilingual:
            mix_src_refs = st.slider("Mix Similarity: Å¹rÃ³dÅ‚o (lewo) â†” Wzorce (prawo)", 0.0, 1.0, 0.7, 0.05,
                                     help="0.7 = 70% wagi dla Å¹rÃ³dÅ‚oâ†”Student, 30% dla Studentâ†”Wzorce")

    st.subheader("Wagi komponentÃ³w")
    w_auto = st.number_input("Waga: Similarity", min_value=0.0, value=0.40, step=0.05)
    w_faith = st.number_input("Waga: WiernoÅ›Ä‡",   min_value=0.0, value=0.35, step=0.05)
    w_lang  = st.number_input("Waga: JÄ™zyk",      min_value=0.0, value=0.15, step=0.05)
    w_style = st.number_input("Waga: Styl",       min_value=0.0, value=0.10, step=0.05)
    st.caption("Wagi nie muszÄ… sumowaÄ‡ siÄ™ do 1 â€” znormalizujemy je automatycznie.")

# ---------- SKALA OCEN ----------
st.markdown("### ğŸ§® Skala ocen (progi % â†’ ocena PL)")
cols = st.columns(5)
with cols[0]: th_5  = st.number_input("5.0 od (%)", 0.0, 100.0, 90.0, 1.0)
with cols[1]: th_45 = st.number_input("4.5 od (%)", 0.0, 100.0, 80.0, 1.0)
with cols[2]: th_40 = st.number_input("4.0 od (%)", 0.0, 100.0, 70.0, 1.0)
with cols[3]: th_35 = st.number_input("3.5 od (%)", 0.0, 100.0, 60.0, 1.0)
with cols[4]: th_30 = st.number_input("3.0 od (%)", 0.0, 100.0, 50.0, 1.0)
st.caption("Upewnij siÄ™, Å¼e progi malejÄ…: 5.0 â‰¥ 4.5 â‰¥ 4.0 â‰¥ 3.5 â‰¥ 3.0")

# ---------- PRZYCISK: ANALIZA + ZAPAMIÄ˜TANIE ----------
if st.button("ğŸ” OceÅ„ tÅ‚umaczenie", type="primary"):
    if not student_translation.strip():
        st.error("WprowadÅº tÅ‚umaczenie studenta.")
    elif analysis_mode == "DwujÄ™zyczny (Å¹rÃ³dÅ‚o â†” Student)" and not source_text.strip():
        st.error("W trybie dwujÄ™zycznym wymagany jest tekst ÅºrÃ³dÅ‚owy.")
    else:
        # --- Przygotowanie danych ---
        raw = reference_translations.replace("\r\n", "\n")
        refs_list = [blk.strip() for blk in raw.split("\n\n") if blk.strip()] if reference_translations.strip() else []
        if len(refs_list) == 1 and "\n" in refs_list[0]:
            refs_list = [r.strip() for r in raw.split("\n") if r.strip()]

        # --- Similarity (global) ---
        crossling_sim = 0.0
        ref_sim = 0.0
        best_ref_text = ""

        if analysis_mode == "DwujÄ™zyczny (Å¹rÃ³dÅ‚o â†” Student)":
            # semantyka ÅºrÃ³dÅ‚oâ†”student
            crossling_sim = crossling_global_similarity(source_text, student_translation) if use_semantics else 0.0
            if include_refs_in_bilingual and refs_list:
                ref_sim, best_ref_text = best_ref_global_similarity(student_translation, refs_list) if use_semantics else (0.0, "")
                # miks: mix_src_refs = waga Å¹rÃ³dÅ‚oâ†”Student
                auto_similarity = mix_src_refs * crossling_sim + (1.0 - mix_src_refs) * ref_sim
            else:
                auto_similarity = crossling_sim
        else:
            # Tryb wzorcowy (Student â†” Wzorce)
            ref_sim, best_ref_text = best_ref_global_similarity(student_translation, refs_list) if (use_semantics and refs_list) else (0.0, "")
            lit_sim, lit_best_ref = best_literal_match(student_translation, refs_list) if refs_list else (0.0, "")
            auto_similarity = (0.7 * ref_sim + 0.3 * lit_sim) if use_semantics else lit_sim

        # --- Ocena koÅ„cowa ---
        sim_pct = round(auto_similarity * 100, 1)
        faith_pct = round(faithfulness / 5 * 100, 1)
        lang_pct = round(language_quality / 5 * 100, 1)
        style_pct = round(style / 5 * 100, 1)

        # Normalizacja wag
        total_weight = w_auto + w_faith + w_lang + w_style
        w_auto_n = w_auto / total_weight
        w_faith_n = w_faith / total_weight
        w_lang_n = w_lang / total_weight
        w_style_n = w_style / total_weight

        final_pct = round(
            sim_pct * w_auto_n +
            faith_pct * w_faith_n +
            lang_pct * w_lang_n +
            style_pct * w_style_n,
            1
        )

        # Ocena literowa
        if final_pct >= th_5: grade = "5.0"
        elif final_pct >= th_45: grade = "4.5"
        elif final_pct >= th_40: grade = "4.0"
        elif final_pct >= th_35: grade = "3.5"
        elif final_pct >= th_30: grade = "3.0"
        else: grade = "2.0"

        # --- Feedback ---
        feedback_text = generate_feedback(sim_pct, faith_pct, lang_pct, style_pct)

        # --- Zapis do tabeli sesji ---
        new_row = {
            "Data": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "Student": student_name,
            "Zadanie/Plik": assignment_name,
            "Tryb": analysis_mode,
            "PodobieÅ„stwo_crossling": round(crossling_sim * 100, 1),
            "PodobieÅ„stwo_wzorcowe": round(ref_sim * 100, 1),
            "Wynik_Å‚Ä…czny": sim_pct,
            "WiernoÅ›Ä‡(1-5)": faithfulness,
            "JÄ™zyk(1-5)": language_quality,
            "Styl(1-5)": style,
            "W_auto": w_auto,
            "W_wiernoÅ›Ä‡": w_faith,
            "W_jÄ™zyk": w_lang,
            "W_styl": w_style,
            "Mix(Å¹rÃ³dÅ‚oâ†”Wzorce)": round(mix_src_refs, 2) if analysis_mode.startswith("DwujÄ™zyczny") else None,
            "Progi(%): 5.0": th_5,
            "4.5": th_45,
            "4.0": th_40,
            "3.5": th_35,
            "3.0": th_30,
            "Wynik_finalny_%": final_pct,
            "Ocena": grade
        }

        # Nadpisywanie lub dodawanie
        df = st.session_state.get("results_df", pd.DataFrame(columns=list(new_row.keys())))
        if overwrite_mode:
            mask = (df["Student"] == new_row["Student"]) & (df["Zadanie/Plik"] == new_row["Zadanie/Plik"])
            df = df[~mask]
        df = pd.concat([df, pd.DataFrame([new_row])], ignore_index=True)
        st.session_state.results_df = df

        # --- WyÅ›wietlenie wynikÃ³w ---
        st.success(f"Wynik koÅ„cowy: **{final_pct}% â†’ ocena {grade}**")
        st.markdown("#### ğŸ’¬ Komentarz automatyczny")
        st.markdown(feedback_text)
        # --- PrzykÅ‚ady niskiej zgodnoÅ›ci per zdanie (auto) ---
examples, ref_label = extract_low_similarity_examples(
    student_text=student_translation,
    analysis_mode=analysis_mode,
    source_text=source_text,
    refs_list=refs_list,
    use_semantics=use_semantics,
    max_examples=3,
    threshold_pct=70  # moÅ¼esz zmieniÄ‡ na 75/80, jeÅ›li chcesz ostrzejsze sito
)

if examples:
    st.markdown("#### ğŸ” PrzykÅ‚ady zdaÅ„ o najniÅ¼szej zgodnoÅ›ci (automatycznie)")
    for ex in examples:
        st.markdown(
            f"**Zdanie {ex['idx']} â€” {ex['score_pct']}%**\n\n"
            f"- **Student:** {ex['stud']}\n\n"
            f"- **{ref_label}:** {ex['ref_or_src']}\n\n"
            f"- **WskazÃ³wka:** {ex['hint']}\n\n"
        )
        # Diff pokazujemy tylko, gdy to porÃ³wnanie jednojÄ™zyczne (w dwujÄ™zycznym to mniej uÅ¼yteczne)
        if not analysis_mode.startswith("DwujÄ™zyczny") and ex['diff']:
            with st.expander("PodglÄ…d rÃ³Å¼nic (skrÃ³t)"):
                st.code(ex['diff'])
else:
    st.caption("Brak zdaÅ„ poniÅ¼ej progu â€” bardzo rÃ³wne dopasowanie ğŸ‘")


        # ZapamiÄ™taj do panelu zdaÅ„
        st.session_state.last_student_translation = student_translation
        st.session_state.last_refs_list = refs_list
        st.session_state.last_use_semantics = use_semantics
        st.session_state.last_analysis_mode = analysis_mode
        st.session_state.last_source_text = source_text
        # ---------- WYNIKI ZBIORCZE + POBIERANIE CSV ----------
st.markdown("---")
st.subheader("ğŸ“Š Zebrane wyniki (sesja)")

# Upewnij siÄ™, Å¼e tabela istnieje
if "results_df" not in st.session_state:
    st.session_state.results_df = pd.DataFrame(
        columns=[
            "Data","Student","Zadanie/Plik","Tryb",
            "PodobieÅ„stwo_crossling","PodobieÅ„stwo_wzorcowe","Wynik_Å‚Ä…czny",
            "WiernoÅ›Ä‡(1-5)","JÄ™zyk(1-5)","Styl(1-5)",
            "W_auto","W_wiernoÅ›Ä‡","W_jÄ™zyk","W_styl",
            "Mix(Å¹rÃ³dÅ‚oâ†”Wzorce)","Progi(%): 5.0","4.5","4.0","3.5","3.0",
            "Wynik_finalny_%","Ocena"
        ]
    )

df_view = st.session_state.results_df.copy()

# Zamiana wybranych kolumn na % w widoku (bez zmiany w oryginalnym DF)
def _fmt_pct(x):
    if pd.isna(x) or x == "":
        return ""
    try:
        # te kolumny sÄ… juÅ¼ w %, ale mogÄ… byÄ‡ floatami; dbamy o caÅ‚e liczby
        return f"{float(x):.0f}%"
    except:
        return x

for col in ["PodobieÅ„stwo_crossling","PodobieÅ„stwo_wzorcowe","Wynik_Å‚Ä…czny","Wynik_finalny_%"]:
    if col in df_view.columns:
        df_view[col] = df_view[col].apply(_fmt_pct)

st.dataframe(df_view, use_container_width=True)

# Åšrednie (tylko jeÅ›li sÄ… dane liczbowe)
if not st.session_state.results_df.empty:
    # Bezpieczne rzutowanie
    def _to_float(series):
        return pd.to_numeric(series, errors="coerce")

    mean_final = _to_float(st.session_state.results_df["Wynik_finalny_%"]).mean()
    # Ocena jako float (np. "4.5" â†’ 4.5)
    mean_grade = _to_float(st.session_state.results_df["Ocena"]).mean()

    st.markdown("### ğŸ“ˆ Åšrednie (sesja)")
    c1, c2 = st.columns(2)
    with c1:
        st.metric("Åšredni wynik ( % )", f"{mean_final:.0f}%" if not pd.isna(mean_final) else "â€”")
    with c2:
        st.metric("Åšrednia ocena (PL)", f"{mean_grade:.1f}" if not pd.isna(mean_grade) else "â€”")

# Pobieranie CSV (oryginalny DF, bez formatowania %)
csv_data = st.session_state.results_df.to_csv(index=False).encode("utf-8")
st.download_button(
    "â¬‡ï¸ Pobierz wyniki jako CSV",
    data=csv_data,
    file_name="wyniki_tlumaczen.csv",
    mime="text/csv"
)

